# MNIST-Multi-Model-
A machine learning benchmarking tool that trains, evaluates, and compares multiple models on the MNIST dataset, generating accuracy, precision, recall, F1-scores, confusion matrices, and visual performance charts.

This project benchmarks multiple machine learning models on the MNIST handwritten digits dataset. It trains Logistic Regression, Decision Tree, Random Forest, SVC, and Gradient Boosting, then evaluates them using accuracy, precision, recall, F1-score, and confusion matrices.

## Features
- Automated MNIST dataset loading and preprocessing
- Trains 5 ML models with tuned hyperparameters
- Generates detailed classification reports
- Saves summary metrics to CSV
- Visualizes accuracy, F1-score, precision, recall, and training time
- Radar chart for overall performance comparison

## Models Included
- Logistic Regression  
- Decision Tree  
- Random Forest  
- Support Vector Classifier  
- Gradient Boosting Classifier  

## Output Files
- `mnist_model_comparison.csv` — summary of model metrics  
- `mnist_performance_comparison.png` — performance visualizations  

## Requirements
Install required libraries:

## How to Run
1. Ensure dependencies are installed  
2. Run the Python script:

## Result
The script prints full evaluation results, identifies the best-performing model, and shows visual comparisons for deeper analysis.

